{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 載入 Selenium 相關模組\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import bs4, random, time\n",
    "import urllib.request as req"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我先…..1.把冰箱雞蛋🥚壓在枕頭下希望孵出小雞🐤（結果想當然爾是被我壓到爛發臭後被我媽發現就被追著打2.在外婆家門口賣外婆的拖鞋一雙100$（差點害外婆沒拖鞋穿…3.小時候特愛買戳戳樂戳了好幾盒後把不喜歡的小玩具放在空的保麗龍戳戳樂盒子貼上白紙畫格子拿去學校賣一格5$…（被老師發現後寫聯絡簿通知家長結果是我被沒收了一個禮拜的零用錢…4.跟弟弟說我是魔女不可以跟別人講這個秘密不然我會變成青蛙🐸（絕對是小魔女抖蕊咪看太多….剛剛洗澡時候突發奇想就想起來這四個我記得小時候鬼靈精怪鬼點子超多！不知道大家小時候有沒有類似這樣很好玩的事情🤣🤣\n",
      "\n",
      "送上我家肥橘🍊寫真一張\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 設定Chrome Driver 的執行檔路徑\n",
    "options = Options()\n",
    "options.chrome_executable_path = \"C:\\\\Users\\\\student\\\\Desktop\\\\model_compar\\\\chromedriver.exe\"\n",
    "\n",
    "#建立 Driver 物件實體，用程式操作瀏覽器運作\n",
    "driver = webdriver.Chrome(options = options)\n",
    "\n",
    "\n",
    "# 連線到PTT股票版 https://www.dcard.tw/f/talk/p/239983442\n",
    "# 取得股票版中的文章標題\n",
    "driver.get(\"https://www.dcard.tw/f/talk/p/239983442\")\n",
    "# driver.get(\"https://www.ptt.cc/bbs/Stock/index.html\")\n",
    "data = driver.page_source #取得網頁的原始碼\n",
    "\n",
    "root = bs4.BeautifulSoup(data, \"html.parser\")\n",
    "titles = root.find(\"div\", class_ = \"sc-ba53eaa8-0 hKkUKs\")\n",
    "for title in titles:\n",
    "    result = title.text.strip().replace('\\n', '').replace(' ', '')\n",
    "    print(result)\n",
    "# tags = driver.find_elements(By.CLASS_NAME, \"title\") # 搜尋class屬性是title的所有標籤\n",
    "# for tag in tags:\n",
    "#     print(tag.text) \n",
    "\n",
    "# 取得上一頁的文章標題\n",
    "# link = driver.find_element(By.LINK_TEXT, \"‹ 上頁\")\n",
    "# link.click() # 模擬使用者點擊連結標籤\n",
    "# tags = driver.find_elements(By.CLASS_NAME, \"title\") # 搜尋class屬性是title的所有標籤\n",
    "# for tag in tags:\n",
    "    # print(tag.text) \n",
    "\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dcard API(沒用到)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# url = \"https://www.dcard.tw/service/api/v2/posts/238632575\"\n",
    "\n",
    "def get(url):\n",
    "    req = urllib.request.Request(url, headers={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/106.0.0.0 Safari/537.36'})\n",
    "    response = urllib.request.urlopen(req).read().decode('utf-8')\n",
    "    return response\n",
    "        \n",
    "def get_single_post(pid):\n",
    "    url = \"https://www.dcard.tw/service/api/v2/posts/{}\".format(pid)\n",
    "    reqsjson = json.loads(get(url)) \n",
    "    for title in reqsjson['content']:\n",
    "        result = title.replace('\\n', '').replace(' ', '') # .text.strip()\n",
    "    print(result) \n",
    "    return reqsjson\n",
    "\n",
    "get_single_post(238632575)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dcard 爬蟲(beautifulSoup 但因403原因所以不能使用)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcardCraw(url):\n",
    "    # 建立一個Request 物件，附加Request Headers 的資訊\n",
    "    # 403：伺服器已經理解請求，但是拒絕執行它，意即與請求一併發送的憑證無效。\n",
    "    request = req.Request(url, headers={\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/106.0.0.0 Safari/537.36\"\n",
    "    })\n",
    "\n",
    "    # data = cloudscraper.create_scraper().get(url).text\n",
    "    time.sleep(random.randint(3,4))\n",
    "    with req.urlopen(request) as response:\n",
    "        data = response.read().decode(\"utf-8\")\n",
    "    # 「解析」原始碼，取得每篇文章的問題\n",
    "    # utf-8(比較省空間)有部分的漢字不能轉換所以要用GB18030編碼\n",
    "\n",
    "    # 讓beautifulSoup協助我們解析HTML格式文件\n",
    "    root = bs4.BeautifulSoup(data, \"html.parser\")\n",
    "    titles = root.find(\"div\", class_=\"sc-ba53eaa8-0 hKkUKs\")  # 用列表顯示全部爬蟲下來的標題\n",
    "\n",
    "    for title in titles:\n",
    "        result = title.text.strip().replace('\\n', '').replace(' ', '')\n",
    "        #印出內文\n",
    "        print(result)\n",
    "    \n",
    "    return result\n",
    "    # titles代表div標籤\n",
    "    # 尋找class = \"title\" 的div 標籤，因為class是保留字，所以寫成class_\n",
    "    # root 代表整個網頁、title是網頁標籤也是網頁標題\n",
    "    # cls 是清空終端機(terminal)\n",
    "    # mode = \"a\"是以附加的方式打開並寫入文件，因為mode = \"w\"會將檔案清空在寫入，mode=\"a\"不會清空"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9bf8e5f6ae5a440c6649c43ab49956741af2ee52909e232ddcd4abcc58504c21"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
